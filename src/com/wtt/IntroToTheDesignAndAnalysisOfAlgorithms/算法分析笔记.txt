1. 绪论
2. 算法效率分析基础
3. 蛮力法
4. 减治法
5. 分治法
6. 变治法
7. 时空权衡
8. 动态规划
9. 贪婪技术
10. 迭代改进
11. 算法能力的极限
12. 超越算法能力的极限

chapter 1

设计过程
	理解问题，
	设计算法
	数据结构
	算法描述
	正确性证明
	算法分析
	为算法写代码

重要的问题类型
	排序: 稳定性与是否需要额外空间(在位)
	查找：
	字符串处理： 字符串匹配
	图： 最短路径，填色问题
	组合问题：
	几何问题： 最近对问题，凸包问题
	数值问题：

基本数据结构
	线性数据结构： 数组，链表  栈，队列，优先队列
	图： 无向图，有向图。
		邻接矩阵，邻接链表
		加权图： 权重矩阵或成本矩阵 加权的邻接链表
	树： 即连通无环图  |E| = |V| - 1
		有根树： 顶点v的深度是根到v的简单路径的长度。
			树的高度是根到叶节点的最长简单路径的长度。（有些教材定义为树包含的层数，这样的高度比路径长度大1）
		有序树： 二叉树，二叉查找树，多路查找树
		二叉树： logN <= h <= n-1
		对于任意的有序树，如果每个节点都只包含2个指针，左指针指向该节点的第一个子女，
		而右指针指向该节点的下一个兄弟，此种方法为先子女后兄弟表示法（first child-next sibling representation).
		这样可以将任意一棵有序树转换成一棵二叉树。
	集合： 位向量表示法，以大量存储空间为代价
				线性列表结构来表示
	字典：从集合中查找，新增和删除一个元素，即动态内容的查找。


chpater 2

分析框架：
	输入规模
	运行时间： 由于具体时间受设备影响，应以基本操作执行次数为准（即内循环执行次数）
			T(n) = Cop * C(n)
			如果C(n) = n(n-1) / 2 ~ n^2/2,则依据上述公式在输入规模翻倍时有T(2n)/T(n) ~ 4.
			所以仅关注指数和常数的增长
	最优，最差和平均效率：
		最优：即某种输入可以得到最小的C(n)值，即内循环次数最小
		平均效率：不是简单的求平均数，而是根据不同的输入类型结合概率分布得出结果
		摊销效率： 多次运行，从而避免单次执行的最差效率
渐进符号和基本效率类型：

	O(g(n)): 增长次数小于等于g(n)的函数集合
	Ω(g(n)): 增长次数大于等于g(n)的函数集合
	Θ(g(n)): 增长次数等于g(n)的函数集合
	即O是上界，Ω是下界，对于Θ有对于所有的n>=n0来说，c2g(n)<= t(n) <= c1g(n)

	有用特性： 算法由2个连续的部分组成，其总体性能由性能较差的部分决定

利用极限比较增长次数： lim(n->∞) t(n)/g(n)的值

非递归算法的数学分析：

	1. 决定用哪个(哪些)参数表示输入规模
	2. 找出基本操作（内循环）
	3. 基本操作次数是否只依赖输入规模，若不是，需要对最差，最优，平均效率分别进行研究
	4. 建立基本操作次数的求和表达式
	5. 至少确定该公式的增长次数.

递归算法的数学分析：

	1. 决定用哪个(哪些)参数表示输入规模
	2. 找出基本操作（内循环）
	3. 基本操作次数是否只依赖输入规模，若不是，需要对最差，最优，平均效率分别进行研究
	4. 对于基本操作的执行次数，建立一个递推关系和对应的初始条件
	5. 解递推式或确立其增长次数


chapter 3 蛮力法

基于问题的描述和定义直接解决问题的办法
1. 选择排序，冒泡排序
2. 顺序查找，蛮力字符串匹配
3. 最近对和凸包问题
4. 穷举查找
5. 深度优先查找和广度优先查找
	dfs: 树向边，回边
	bfs: 树向边，交叉边

chapter 4 减治法

原问题和子问题的关系，可以从顶至下（递归）或从底向上（也叫增量法）解决。
1. 减去一个常量（考虑n-1的情况）
2. 减去一个常量因子（大多数应用因子为2）
3. 减去的规模是可变的（计算gcd的欧几里得算法）

1. 插入排序
	从顶向下思考: 对n个数进行排序，假设前面n-1个数已经排好了，
	最后一个数要排序应遍历前面的数列，插入进去从而实现有序，这是递归实现
	但从底向上实现效率更高,n从1开始循环增长到n
2. 拓扑排序
	1. 基于dfs算法的逆后序排列
	2. 基于减治法的逐个删除入度为0的顶点
	上面得到的解不同，所以可以有多个可选解
3. 生成组合对象的算法
	1. 生成排列：
		从底向上生成排列，最小变化算法（minimal change)
		johnson Trotter（对较小的n生成排列）算法
		按字典序排列算法
	2. 生成子集
		所有集合子集的集合称为幂集
		与子集一一对应的位串
		最小变化的生成位串： 二进制反射格雷码（它是循环的，最后一个位串与第一个位串只相差一位）BRGC算法
4. 减常因子算法
	1. 二分查找
	2. 假币问题： 找出一堆硬币中的假币。（将硬币分成3堆要比分成2堆要好）
	3. 俄式乘法： 为计算机通过移位即可完成二进制的折半和加倍提供了基础
	4. 约瑟夫斯问题： （这个故事告诉我们给别人干活时，明白领导的真正意图非常重要）
		每个人从1开始轮流报号，如报1的人杀死号码为2的人，依次进行
		J(2k) = 2J(k) - 1
		J(2k+1) = 2J(k) + 1
		闭合式最佳解： J(6) = J(110|2) = J(101|2) = J(5) 二进制向左循环移位一次

5. 减可变规模算法

	1. 计算中值和选择问题
		寻找中值： lomuto划分 用于划分的2个下标
		快速排序
	2. 插值查找
		对于一个有序的列表，通过线性公式求出待查找值v对应的x下标值，比较A[x]与v的值，比较后再减小规模
		类似于在字典靠前的部分查找单词book
		小规模排序二分查找更快，更大规模插值查找更快
	3. 二叉查找树的查找和插入
		根据树的形状和高度的不同，相同的数据减小的规模无法确定，所以是可变的
	4. 拈游戏
		类似象棋中局面概念一样，每次拿1<=n<=m个棋子，n=0，m+1，...是败局
		从底向上分析，通过数学归纳法可以得到赢或输的模式
		对于多堆的棋子，棋子个数的二进制之和若包含一个1，则当前局面为胜局，
		若和中全部为0时，则当前局面为败局。

chapter 5 分治法

	1. 将一个问题划分成若干子问题，最好子问题规模相同
	2. 对这些子问题求解
	3. 有必要时合并子问题的解
通用分治递推式：
T(n) = aT(b/n) + f(n) f(n)是将结果合并起来所消耗的时间
即原问题可以分成b个子问题，其中a个需要求解。
当a = 1时，即只需要解决一个问题时，即变成减常因子算法

1. 归并排序
2. 快速排序
	Hoare划分： 从左右两端同时扫描再交换的算法
	对于严格递增已经有序的数组，快排的效率是最差的，所以一般在排序前需要打乱数组
3. 二叉树遍历及其相关特性
	前序： 根左右
	中序: 左中右
	后序： 左右根
4. 大整数乘法和Strassen矩阵乘法
	1. 大整数相乘
		相同位数的乘法（不同可以前面补0）,分成2半分治处理。
		即发现两个2位数相乘可以不用4次乘法运算，通过分治3次就可以实现
		即其效率不是普通的n^2,而是n^1.5(log2 3)
		java中的BigInteger
	2. Strassen矩阵乘法
		对于2个2X2的矩阵，普通算法需要8次乘法，4次加法；
		Strassen算法需要7次乘法，18次加减法，当阶数趋近于无穷大时，其效率更高
		对于高阶的矩阵，可以用0补全划分成(n/2) X (n/2)的矩阵
		因为n阶矩阵的乘法得到的结果是n阶的，它的每一个元素都是左边的行元素和右边的列元素相乘得到，
		即n^2个元素中的每个元素都是经过n次乘法得到的，所以一共需要的乘法运算次数是n^2 * n = n^3个。
		Strassen通过递推式M(n)=7M(n)，M(1) = 1可以得出
		M(n) = n ^ 2.87(n ^ log2 7)
		同样通过递推式可以得出Strassen额外需要的加法次数的增长次数与乘法相同
		目前矩阵乘法最快的算法达到了n^2.376,而其理论下界是n^2
5. 用分治法解最近对问题和凸包问题
	1. 最近对问题
		在x坐标轴的中位线上画一条垂线，将点划分成两半进行分治处理
		然后在归并左右两边的最短距离时在一个矩阵内考虑即可。
		这与归并排序算法很相似
	2. 凸包问题
		快包算法： 和快排类似
		相当于一刀切开西瓜，上面一半叫上包，下面一半叫下包，
		在上包中找到距离切开线最远的点，使得三角形pl pMax pr 面积最大
		三角形外的2个半弧形即是所求上包的2部分，继续用三角形重复切分这个过程，知道上包为空，
		再将所有pMax点联合起来即可得到上包的所有极点。
		下包重复这个过程，即可得到整个的凸包。
		（代码实现时，三角形的面积可以用行列式的一半来计算，AB,AC的叉乘/外积是平行四边形的面积，
		三角形是它的一半）

Chapter 6 变治法

	3中主要类型
	1. 实例化简：变为更简单的实例，该新实例有一些特殊的属性，使得它可以更容易被解决。
	2. 改变表现：变为同样实例的不同表现
	3. 问题化简：变为另一个问题的实例

1. 预排序
	1. 检验数组中元素的唯一性
		nlogn, n-1 整体性能是nlogn
	2. 模式计算
		找出列表中出现频率最高的数字（即模式）： 未排序前需要辅助的map集合记录每个不同数字的频率，最差是n^2,
			但经过预排序后，找出邻接次数最多的等值元素即可。
	3. 查找问题
		在列表中找到某个特定的元素，蛮力法n次比较，预排序nlogn,但如果多次查找，预排序更好。
一般处理几何计算问题需要预排序，上章的最近对和凸包问题就用到了；另外拓扑排序，基于贪婪技术的算法也用到了。

2. 高斯消去法
	通过初等变换得到一个上三角矩阵，x(n)通过最后一行解出，x(n-1)通过将x(n)代入n-1行求出。
	还需考虑到除数为0时直接进行行交换的情况，以及舍入误差的问题
	通过优化后其效率为n^3.
	1. LU分解
		利用高斯消去法的中间过程的乘数L和结果U，对任意的Ax = b的方程组，因为LU = A
		其等价于LUx = b, 设Ly = b => y的结果，再求 Ux = y => x的结果。
	2. 计算矩阵的逆
		想要求逆，即求出逆矩阵的n^2个未知系数，可以利用LUx(j) = e(j)求出逆矩阵的第j列（1<=j<=n),e(j)代表单位矩阵的第j列。
	3. 计算矩阵的行列式
		按照行列式的递归定义求解行列式，detA = sum（1，n)s(j)a(1j)detA(j)
		它求detA(n)需要n!的数量级，利用高斯消去法，
		因为一个上三角矩阵的行列式等于其主对角线上的元素的乘积。
		 Ax = b;方程的系数矩阵detA != 0时，这个方程才有唯一解（行列式是线性变换的比率大小！！！）
		 可以用克拉默法则来求解。xj = detAj / detA; An是A的第j列用b替换得到的矩阵

3. 平衡查找树
	1. AVL树
		通过旋转将一颗不平衡的二叉查找树转化为平衡的树的过程即是实例化简的过程。
		平衡二叉树指每一个节点的高度差是最多为1的二叉查找树。
		4种旋转：
		1. 右单旋 R
		2. 左单旋 L
		3. 左右双旋 LR （先左旋下一层子树，再右旋上一层子树）
		4. 右左双旋 RL （先右旋下一层子树，再左旋上一层子树）
	2. 2-3树 （改变表现）
		一个3-节点包含2个键，它同是也是有序的，所有的叶子都位于同一层，即它是高度平衡的
		2-3树有一种重要的一般性形式，即B树。

4. 堆和堆排序(改变表现)
	1.堆的概念
		一颗完全二叉树，每层都是满的，除了最后一层最右边的元素可能为空；
		堆特性： 每个节点的键大于等于子女的键。
		键值是从上到下排序的，即从根到任意一个叶子的路径上，键值的序列是递减的。
		但不存在左右的关系，即同一节点的左右子树之间没有关系。
		用数组来实现堆：
			父母节点在前n/2个位置中，最底层的叶子节点在后n/2个位置中
			父母节点为i(1<=i<=[n/2]),其子女为2i和2i+1。
			叶子节点为i(2<=i<=n),其父母为[i/2].
		构造堆：
		1.自底向上： sink.
		2. 自顶向下： swim.
	2. 堆排序
		1. 构造堆。
		2.删除根（最大键），放到数组后面，重新堆化后重复这个过程直到排序完成。
		堆排序的时间效率也为nlogn
5. 霍纳法则和二进制幂(改变表现)
	1. 霍纳法则
		已知x,求多项式的值，以及该多项式的特殊情况求x^n的值。

			p(x) = a(n)x^n + a(n-1)x(n-1) + ... + a1x + a0;

		把x作为公因子提出来变为
			p(x) = (...(a(n)x + a(n-1))x+...)x + a0
		由其特定模式即可以得到霍纳法则的算法
		算法代码
		Horner(int[] P, x) {
		 int p = P[n];
		 for (int i = n-1; i >= 0; i--) {
		 	p = x * p + P[i - 1]
		 }
		 return p;
		}
		霍纳法则用n次乘法不仅求出了x^n的值，还求出了其他n-1项的值（中间结果）。
		综合除法算法，对于某些特定x0，中间结果为商的系数，最终结果为余数。
	2. 二进制幂
		用霍纳法则计算x^n时，退化成了蛮力的自乘，没有效果。
		一个正整数的二进制表示,如13 = 1101，
		则13 = 1 * 2^3 + 1 * 2^2 + 0 * 2^1 + 1 * 2^0;
		x^n = x^p = x ^ (b(I)2^I + ... + b(i)2^i + ... + b(0))
		对p使用霍纳法则，观察x^n的结果，可以得出规律。
		算法
		leftRightBinaryExponention(a, int[] b){

			int product = a;
			for(i = I - 1; i >= 0; i--) {
				product = product * product;
				if(b[i] == 1) product = a * product;
			}
			return product;
		}
		该算法将a^n由蛮力的n-1次乘法变为log(n)次（二进制表示的位数长度为log(n))
		另不用霍纳法则，对指数进行列项，从小向大平方，即从右向左。
		RightLeftBinaryExponention(a, int[] b) {
			int term = a;
			if(b[0] = 1){
				product = a;
			}else{
				product = 1;
			}
			for(int i = 1; i <= I; i++) {
				term = term * term; // a^2
				if(b[i] == 1) {
					product = product * term; // 以a^2增长
				}
			}
			return product;
		}
		这也是对数级别的，可以不直接使用对数表示。
6. 问题化简
	即将目标问题简化为某个有已知算法的问题的过程。
	前面求x^n化简为可以应用霍纳法则的多项式问题，
	以及凸包中判断一个点在某条直线左边的问题简化为求某个行列式的符号问题
	都属于问题化简类别。
	1. 求最小公倍数。
		在已知欧几里得算法求gcd的情况下，如何求最小公倍数？
		根据定义发现gcd * lcm = m * n;
		即 lcm = m * n / gcd;
		从而将lcm的问题转化成了gcd的问题。
	2. 计算图中的路径数量
		图的邻接矩阵的n次幂可以指示出2个顶点之间的路径的数量
	3. 优化问题的化简
		已知一个函数的最大值，怎么求最小值？
		可以发现	 minf(x) = -max(-f(x))
		求函数f(x)极值点的过程也是微积分的过程，该问题转化为求f'(x)=0的问题，变为解方程
	4. 线性规划
		很多决策最优化问题都可以转化为线性规划问题
		该问题的经典解决算法是单纯形法和卡马卡算法，而对于离散的线性规划问题还没有一个多项式级的求解算法
		背包问题也可以转化为线性规划问题，虽然效率不高，但可以用来检验算法的正确性。
	5. 简化为图问题
		很多问题可以转化为图的问题，顶点表示可能的状态，边表示状态的转移，这种图叫做状态空间图（state-space graph).
		农夫带狼，羊，白菜过河的问题是从状态pwgc||变为状态||pwgc的最短路径问题
		状态空间图是人工智能的一个重要主题。

Chapter 7 时空权衡
	空间换时间
		输入增强： 对问题的部分或全部输入做预处理，然后将获得的额外信息进行存储以加速后面问题的解决。
		预构造：在实际之前处理并只涉及存储结构。
	动态规划： 重复子问题的解记录在表中。

	1. 计数排序
		比较计数排序： 用一个列表记录每个元素比它小的元素的个数，按此进行排序。
		分布计数： 根据频率和分布值对列表从右往左扫描依次放入新数组中，
		放入位置由分布值（该元素最后出现的位置）确定，每放入一个元素分布值减一，直到扫描完成。

		该算法为线性效率，因为其仅仅对列表扫描2遍，第一遍统计频率，并由频率得出分布值。
		第二遍扫描元素依次将其放入正确位置，它比快排算法效率还高的原因是因为它的元素值的取值区间已知。

	2. 字符串匹配中的输入增强技术
		蛮力法效率最差为O(nm),平均为O(n+m)
		对模式进行预处理得到的信息存储在表中，在查找中使用这些信息从而提高效率。
		Knuth-Morris-Pratt算法和Boyer-Moore算法（区别是前者从左往右匹配模式，后者从右向左）
		1. Horspool算法
			1. 用模式的长度m和模式及文本中用到的字母表构造一个移动表，它的索引是字母，值是移动的距离。
			2. 将模式与文本开始处对齐。
			3. 开始匹配，要么所有m个字符都匹配，要么遇到一对不匹配的字符，那么向右移动模式的最后一个字符
			在移动表中的距离。
		Horspool算法最差效率为O(nm),但对于随机文本，效率为O(n)

		2. Boyer-Moore算法
			1. 与Horspool算法一样构造坏符号移动表
			2. 构造好后缀移动表
			3. 将模式与文本开始处对齐
			4. 进行实际匹配
			实际使用还是Horspool算法较多
	3. 散列法
		开散列： open hashing 也叫分离链separate chaining
		闭散列： closed hashing 也叫开式寻址opening addressing

		1. 开散列（分离链)
			hashMap的实现方式
			散列函数大致均匀的将n个键分布在散列表的m个单元格中，比率α = n/m称为负载因子，它也是单个链表的长度
			成功查找平均需要查找一半的长度，即1+α/2,不成功查找为α。
			负载因子最好和1相近，远小于1则有很多空链表，远大于1则链表长度太长，查找时间太长。
			在与1相近的情况下，经过常数时间的散列函数计算，比较1,2次（依据α的值）就可以完成查找。

		2. 闭散列（开式寻址）
			线性探测法
				同样经过散列函数找到具体数组的位置，如果冲突就向后检查下一格，如果为空就插入。
				一系列的单元格称为聚类，聚类增大影响性能，可以用双散列法，该法在碰撞发生后不是向后逐个检查，
				而是根据一个质数跳跃检查，但当表快满时，性能也会恶化，次时应该重散列，把所有的键放到一个更大的表中。

		渐进时间效率（散列法平均O(1),最差O(n);平衡二叉树平均和最差都是O(lgN))
		有序性 散列法经过散列后有序性丢失。
		可扩充散列法可以存储磁盘上大型字典，散列得出某个存储段，将其中所有键转到内存中再进行具体查询。
	4. B 树
		最重要的索引结构是B树。
		B树是2-3树的扩展，一个节点可以有多个键。
		一个次数为m(m>=2)的B树的特征（次数=最大键数-1？）
		1. 树的根要么是一个叶子（所有的键都在一个节点中，每个键的左右都是空指针），
			要么有2到m个子女（一个节点有2到m个键）
		2. 除了叶子和根，中间的父母节点只有m/2到m-1个键（由左右子树的性质决定，最少的键数=根下最多的子女=m/2)
		3. 这颗树是完美平衡的，它的所有叶子都在同一层上。
		当用B树存储一个大型数据文件时，B树的节点通常和磁盘的页相对应，所以访问的树节点个数成了性能指标，
		这个个数为树的高度加一
		经过B树的性质（一个节点包含的最少键数，叶子层至少包含的节点数）推导可以得出
		在B树中查找是一个效率为log(n)的操作，在实际的应用中磁盘访问次数很少超过3次。
		B树的插入和删除也是log(n)级别的操作。
		可以把数据记录连续插入初始为空的树中来构造一棵B树，这时叶子和上层节点中的键组成了一颗作为索引的B树，
		整个结构也被称为B+树。
	一般来说，空间换时间更为普遍。

chapter 8 动态规划
	例子：斐波那契数列的从底向上解决，根据递推关系式只存储最后2个元素值即可解决
	最优化法则： 任一问题的最优解都是由其子实例的最优解构成的。
	此法则绝大多数情况都是成立的。

	1. 三个基本例子
		1. 币值最大化问题
			一排硬币，币值并不一定两两不同，如何选择硬币，使得其原始位置不相邻的情况下，总金额最大？
			F(n) = max{c(n) + F(n-2), F(n-1)} n > 1
			F(0) = 0, F(1) = c1
			CoinRow(int[] C) {
				F[0] = 0;
				F[1] = C[1];
				for(int i=2;i<=n;i++){
					F[n] = max(F[i-2]+C[i], F[i-1]);
				}
				return F[n];
			}
			具体哪些硬币需要回溯算法找到最大值
		 2. 找零问题
		 	需找零金额为n,最少用多少个d1<d2<...<dm的硬币？
		 	F(n) = min{F(n-dj)}+1  n>=dj
		 	F(0) = 0;
		 	F(n)需要找到所有的F(n-dj)中最小的值
		 	ChangeMaking(D[1...m], n){
		 		F[0] =0;
		 		for(int i = 1; i <= n; i++) {
		 			temp = infinite,j = 1;
		 			// 将temp与每个F[n-dj]比较，找出最小值
		 			while(j <= m && i >= D[j]) {
		 				temp = min(F[i-D[j]], temp)
		 				j++;
		 			}
		 			F[i] = temp + 1;
		 		}
		 		return F[n];
		 	}
		 	具体哪些硬币需要回溯算法找到最小值
		 3. 硬币收集问题
		 	一个n X m的木板上放有一些硬币，一个机器人从左上角去往右下角，怎么收集最多的硬币？
		 	F(i,j) = max{F(i-1,j), F(i,j-1)} + c(ij),  1<=i<=n,1<=j<=m
		 	F(0,j) = 0, 1<=j<=m; F(i,0) = 0, 1<=i<=n
		 	有单元格(i,j)中有硬币，c(ij) = 1,否则为0
			RobotCoinCollection(C[1..n, 1...m]) {
				F[1,1] = C[1,1],
				for(int j = 2; j <= m; j++) {
					F[1, j] = F[1, j-1] + C[1,j];
				}
				for(int i=2; i <= n; i++) {
					F[i, 1] = F[i - 1, 1] + C[i, 1];
					for(int j = 2; j <= m; j++) {
						F[i, j] = max(F[i - 1, j], F[i, j - 1]) + C[i, j];
					}
				}
				return F[n, m];
			}
	2. 背包问题和记忆功能
		1. 背包问题
			用2个维度解决这个问题，一个维度i是序号，第一个物品的重量是w1,价值是v1;
			另一个维度j是总重量w.
					|	max{F(i-1,j), v(i)+F(i-1, j-w(i))},  j-w(i)>=0 //第i个物品能放进背包
			F[i,j] =| 	F(i-1, j),  //第i个物品不能放进背包
			j>=0时，F[0,j] = 0; i>=0时，F[i,0] = 0
			要求F[n,W]
			具体求解可以画出动态规划表，通过回溯表的计算过程可以得出最优解的物品列表
			时间和空间效率都是O(nW),求解具体过程为O(n)
		2. 记忆化(Memory Function)
			针对自顶向下的算法，只对必要的子问题进行求解，可以像自底向上一样构造一个表，
			表中数据全部初始化为null, 取值时如果为null,计算后将值放入其中，若不为null,则取该值，
			避免第二次计算。

			递归记忆法自顶向下解决背包问题
			MFKnapsack(i, j) {
				//除了0行和0列初始化为0外，其他单元格初始化为-1
				if (F[i, j] < 0) {
					if(j < Weighs[i]) {
						value = MFKnapsack(i-1, j);
					}else{
						value = max(MFKnapsack(i-1, j), Values[i]+MFKnapsack(i-1, j-Weighs[i]));
					}
					F[i,j] = value;
				}
				return F[i,j];
			}
			求解MFKnapsack(n, w)即可。
			记忆功能时间效率和从底向上是一样的，空间效率在自底向上是最高的。
	3. 最优二叉查找树
		有n个从小到大排列的数，每个数被查找的概率不一定相同，需要结合概率求平均最少的查找次数和树结构？
		以a(k)为根，C(i,j)代表从ai到aj区间的查找次数，最后要求C(1,n)（a1到an的平均查找次数）
		这里的平均结合概率来计算
		C(i,j)
		 = min{p(k) * 1 + sum(s, i, k-1)(p(s) * (ak左子树层数+1)) + sum(s, k+1, j)(p(s) * (ak右子树+1))}
		 = min{C(i, k-1) + C(k+1, j)} + sum(s,i,j)p(s)
		1<=i<=n+1,C(i,i-1) = 0(为负区间，空树)
		1<=i<=n, C(i,i) = p(i)(根据上述公式可以求得)
		根据上述2个初始条件可以画出二维图（行从1开始到n+1,列从0开始到n)，这样对角线全为0,其(i,i)对应斜线为对应概率值，
		根据递推公式直到求出最右上角的值。
		把每次求得最小值的k值（即每个区间的根节点a(k）记录下来即可以得到具体的二叉树图

	4. Warshall算法和Floyd算法
		1. Warshall算法
			可以用dfs或bfs生成传递闭包，但是这需要针对每个顶点都遍历一次图，效率较低，更好的算法为Warshall算法
			一系列矩阵R0,R1,...Rk,...Rn
			R0意味着路径中没有中间顶点，Rk意味着路径的顶点序号不大于k
			可以分析发现，R(ij)(k) = 1时可能的路径有2种情况，不包括顶点k,则R(ij)(k-1) =1,
			或者包括顶点k,则可以将路径化简为R(ik)(k-1) = 1并且R(kj)(k-1) = 1.
			该递推关系可以简化为R(ij)(k) = R(ij)(k-1)	or {R(ik)(k-1) And R(kj)(k-1)}
			for k 1 to n
				for i 1 to n
					for j 1 to n
						R(ij)(k) = R(ij)(k-1)	or {R(ik)(k-1) And R(kj)(k-1)}
			return R
		2. 计算完全最短路径的Floyd算法
			与Warshall算法相似，用一系列的矩阵递推得到最终的最短距离矩阵(路径上的顶点编号不大于k)
			k>=1时，d(i,j,0) = w(i,j)时，d(i,j,k) = min{d(i,j,k-1), d(i,k,k-1)+d(k,j,k-1)}.
			for k 1 to n
				for i 1 to n
					for j 1 to n
						D[i,j] = min{D[i,j], D[i,k]+D[k,j]}
			return D
			立方级别的算法

chapter 9 贪婪技术
	不同面值的硬币用最少的个数凑成指定金额，从最大币值的硬币尽可能多拿开始，一直向后取完为止。
	有些情况可以得到最优解，有些情况得不到。
	贪婪法建议通过一系列步骤来构造问题的解，每一步都对目前构造的部分解做一个扩展，直到获得完整解为止。
	其中每一步需要满足以下条件：
	1. 可行的： 在问题约束内
	2. 局部最优： 所有可行选择中的局部最优选择
	3. 不可取消： 选择一旦做出，后面无法改变
	通常用数学归纳法证明贪婪算法在每一步获得的部分解能够扩展到全局最优解。
	二是证明每一步都选择比其他算法好
	三是根据输出结果证明贪婪算法的最终解为最优算法

	1. Prim算法
		每一步都选择权重最小的横切边，为了确定这条边（或者这个距离树最近的顶点）,
		需要对每个顶点赋予2个值，离该顶点最近的树中的顶点名称和该横切边的权重。
	2. Kruskal算法
		按照全部边的权重大小进行排序，每一步将最小权重边加入到一个空图中，此过程中这个图不一定是联通的。
		如果构成了回路，说明这两个顶点都在树中，跳过即可。
		查找和合并元素的混合操作
		快速查找：quick find
		快速合并：quick union
	3. Dijkstra算法
		加权连通图的单起点最短路径问题：
			它要求的是一组路径，起点到每一个其他顶点的路径是最短的，其中某些路径可能会有公共边。
		Dijkstra算法只能适用于不含负权重的图
		最开始选择离起点最近的顶点，其次选择第二近的顶点，依次类推...
		在中间过程中，整个图分成以起点为核心的树与其他不在树中的边缘顶点集合，求出所有边缘顶点到树的最近距离，
		假设这个距离最近的边上树中的顶点是u,边缘顶点是u*,起点是s,则W(uu*) + d(su)的和最小的值的顶点为
		下一个要加入到树中的顶点。
		每个顶点需要2个标记，一个是到顶点的最短距离，一个是该路径上它的父母顶点。

		算法思想为每加入一个顶点到树中，与该顶点相邻的边缘点都要将两边的路径和与现有的最短路径进行比较，
		即这些点的最短路径需要全部刷新，刷新过后，进入下个循环时再从索引最小优先队列中取最小值，
		这样每一步就拿到最短路径了。
		（这里也体现了贪婪算法的思想，每一步都是最短的路径点，取完后更新所有相邻点的最短路径，下次再取，直到取完为止）

		Dijkstra和Prim算法很相似，它们处理的都是加权连通图，
		但Prim要求最小生成树，直接比较各横切边的权重即可；
		而Dijkstra算法要求最短路径，寻找最短路径长度需要把边的权重相加。

	4. 哈夫曼树及编码
		（文本文件编码方式与内容的分离是乱码问题的根源所在)
		对文本中的字符用位串(如用点，线或0,1构成）替代以进行编码
		定长编码： 定长一字节标准ASCII码的实现，定长2字节的UniCode编码
		变长编码： 问题在于如何区分开每个字符的编码？ UTF-8编码
				(变长方案通过在高位中使用一些特定字符，该字符在低位不会作为编码元素使用，相当于牺牲了可编码空间)
			   （编码有容量与效率的矛盾）
			   	自由前缀码所有代码字都不是另一个代码字的前缀（即不会出现一组串既可以作为整体解码，
			   	又可以拆分成2个有编码含义的字母，即上面说的高低位的区分），这样可以简单扫描字符串，
			   	简单用字母替换与代码字相同的一组比特位即可。

		可以用一颗树来构造这样一套和字母表一一对应的前缀码。
			这树所有的左节点都为0，右节点为1，所有的叶子节点就对应着每一个字母。
			这样从根到叶子节点的路径就够成了该字符的编码，不存在从一个叶子到另一个叶子的简单连续路径，
			所以一个代码字不会是另一个代码字的前缀。解码时寻找一套
			任何这样的树都能生成这样一套编码，那么如何让较短的串（即较短的路径）赋予高频用词，
			较长串赋予低频用词。
		哈夫曼编码算法,将每个字母的作为一棵单节点树，频率作为其权重当做节点的值，
		取节点中权重最小的2个单节点树合并成一棵树，树的新根节点值是子女节点的权重和，然后这颗树再同
		其他的单节点树进行权重比较，再取权重最小的2棵树进行合并直到得到一棵树。

		即每一步都取最小的2棵权重树，也符合贪婪的定义。

		（这样相当于从的树的最底层向根处构造，权重越大其被纳入树的时间越晚，离根也越近，从而最终的编码长度也越短。）
		哈夫曼算法的压缩率（指某变长编码的长度乘以概率得到的平均编码长度比用定长编码实现的固定长度节省的比值）

		哈夫曼编码是一种最重要的文件压缩方法，除了简单通用外，它还是一种最优编码（在字符出现概率独立，且事先已知的情况）
		哈夫曼算法可以用来解决最优决策树的问题，该树中只有叶子节点可被赋值。
		（与最优二叉平衡树不同，它是所有节点都可以放值，它考虑的是某个区间内不同节点作为根节点形成的多棵树中所有节点
		被查找到的平均概率（概率高度乘积和））

		需寻找最小加权路径树，加权路径为所有叶子到根的路径长度与该叶子的值的乘积和。
		如在n个数中猜测一个数，若每个数出现的概率不同，用哈夫曼构造出这样的决策树可以使得平均猜中该数所需的问题数最小。

Chapter 10 迭代改进

		通过对问题的一个初始解进行不断的优化直到无法再优化后得到的解决方案。

		1、单纯形法
			线性规划基本问题，几何意义上的可行区域问题，求目标函数与可行区域的极值点。
			Z=ax+by是一组斜率相同的平行线，称为水平线。
			如果可行区域为空，则该问题被称为不可行的（infeasible)。
			如果可行区域无界，则目标函数可能有最优解，也可能没有最优解。没有最优解的情况称为无界的问题。

			极点定理：可行区域非空的线性规划问题都有最优解，且最优解总能在一个极点上找到。
			在使用单纯形法前，必须将问题转化为一种标准形式：
				1. 必须是一个最大化问题
				2. 所有约束都是线性方程的形式
				3. 所有变量都必须是非负的
			不等式可以用松弛变量转化成等式。如x+y<=4可以转化为x+y+u=4,u>=0
			如果没有非负限制，例如原变量x可以写成 x = x1 - x2,x1>=0,x2>=0
			m个等式的n元方程(n>=m)可以将(n - m)个变量置为0进行解方程操作。
			其中被置为0的变量称为非基本基向量，不为0的变量组为基本解，如果一个基本解的
			所有坐标值都非负，则该基本解称为基本可行解。

			单纯形法就是通过设置不同的基向量，经过矩阵的线性变换，求得基可行解（可行域顶点），判断该
			解是否是最优，否则继续设置另一组基向量，重复执行上述步骤，直到找到最优解。所以单纯形法是一个
			循环迭代的过程。

		2. 最大流量问题
			一个n个顶点的加权连通图，有一个源点（无输入边），一个汇点（无输出边），每条边的权重为正整数，称为容量，
			这样的有向图称为流量网络。
			流量守恒要求： 流入的能量总和等于流出的能量总和。因此源点的总输出流等于汇点的总输入流，该值也称为流的值，
			最大流量即求这个最大值的过程。
			即从起点出发到终点，面对不同粗细的管道，在流量守恒的限制下，如何能够从起点到终点传递最多的信息。
			这里用迭代法，不断寻找流量增益路径。
			因为最大流量的有向性（起点到终点），所以路径上对应的边可以分为前向边和后向边，前向边需要流量尽可能大，
			后向边需要流量尽可能小，对于中间的边，可以取前向边的未使用容量和后向边的流量的较小值作为流量的增量。

Chapter 11 算法能力的极限

	计算算法的效率下界，即求该算法求解问题需要的最少工作量。

	决策树可以帮助找到效率下界。

	复杂性理论：
		哪些问题可以在多项式时间内解决？P，NP,NP完全问题。复杂度被分为两种级别，其中后者的复杂度无论如何都远远大于前者：
	一种是O(1),O(log(n)),O(n^a)等，我们把它叫做多项式级的复杂度，因为它的规模n出现在底数的位置；
	另一种是O(a^n)和O(n!)型复杂度，它是非多项式级的，其复杂度计算机往往不能承受。
	多项式 Polynomial
	P类问题指可以在多项式时间内解决的问题
	NP类问题(Non-Deterministic Polynomial, 非确定多项式，非确定即猜测)指可以在多项式时间内验证一个解
	或猜出一个解的问题之所以定义NP问题，因为通常只有NP问题才可能找到多项式的的算法。
	即实际探讨的是P和NP类问题的关系。
	所有的P问题都是NP问题，即能在多项式时间解决的问题必定是可以在多项式时间内验证的。
	P == NP？NPC(NP-complete)问题指出可能并不相等。
	NP可以约化为NPC问题，约化即问题的时间复杂度更高，应用范围更广。
	NPC问题即是所有NP问题都可以约化为它的一个NP问题。
	NP-hard问题是所有NP问题都可以约化为它，但它本身不一定需要是NP问题的问题。

	（什么是非确定性（Non-Deterministic）问题呢？有些计算问题是确定性的，比如加减乘除之类，你只要按照公式推导，
	按部就班一步步来，就可以得到结果。但是，有些问题是无法按部就班直接地计算出来。
	比如，找大质数的问题。有没有一个公式，你一套公式，就可以一步步推算出来，下一个质数应该是多少呢？
	这样的公式是没有的。再比如，大的合数分解质因数的问题，有没有一个公式，把合数代进去，就直接可以算出，
	它的因子各自是多少？也没有这样的公式。这种问题的答案，是无法直接计算得到的，只能通过间接的“猜算”来得到结果。
	这也就是非确定性问题。而这些问题的通常有个算法，它不能直接告诉你答案是什么，但可以告诉你，
	某个可能的结果是正确的答案还是错误的。这个可以告诉你“猜算”的答案正确与否的算法，
	假如可以在多项式（polynomial）时间内算出来，就叫做多项式非确定性问题。
	而如果这个问题的所有可能答案，都是可以在多项式时间内进行正确与否的验算的话，就叫完全多项式非确定问题。
	完全多项式非确定性问题可以用穷举法得到答案，一个个检验下去，最终便能得到结果。
	但是这样算法的复杂程度，是指数关系，因此计算的时间随问题的复杂程度成指数的增长，很快便变得不可计算了。
	人们发现，所有的完全多项式非确定性问题，都可以转换为一类叫做满足性问题的逻辑运算问题。
	既然这类问题的所有可能答案，都可以在多项式时间内计算，人们于是就猜想，是否这类问题，存在一个确定性算法，
	可以在多项式时间内，直接算出或是搜寻出正确的答案呢？这就是著名的NP=P？的猜想。
	解决这个猜想，无非两种可能，一种是找到一个这样的算法，只要针对某个特定NP完全问题找到一个算法，
	所有这类问题都可以迎刃而解了，因为他们可以转化为同一个问题。
	另外的一种可能，就是这样的算法是不存在的。那么就要从数学理论上证明它为什么不存在。
	有些看来好像是非多项式的问题，其实是多项式问题，只是人们一时还不知道它的多项式解而已。）

	逻辑电路问题。这是第一个NPC问题。其它的NPC问题都是由这个问题约化而来的。
	因此，逻辑电路问题是NPC类问题的“鼻祖”。
	即给定一个逻辑电路，问是否存在一种输入使输出为True，这即逻辑电路问题。

	数值分析

	1. 如何求下界 Ω(大于等于g(n)，求下界)
		1. 平凡下界
			对问题的输入和输出项进行计数，这样的计数产生了一个平凡下界。

			（旅行商问题(TravelingSalesmanProblem，TSP)是一个经典的组合优化问题。
			经典的TSP可以描述为：一个商品推销员要去若干个城市推销商品，该推销员从一个城市出发，需要经过所有城市后，回到出发地。
			应如何选择行进路线，以使总的行程最短。从图论的角度来看，该问题实质是在一个带权完全无向图中，
			找一个权值最小的Hamilton回路。由于该问题的可行解是所有顶点的全排列，随着顶点数的增加，会产生组合爆炸，
			它是一个NP完全问题。由于其在交通运输、电路板线路设计以及物流配送等领域内有着广泛的应用，
			国内外学者对其进行了大量的研究。早期的研究者使用精确算法求解该问题，
			常用的方法包括：分枝定界法、线性规划法、动态规划法等。但是，随着问题规模的增大，
			精确算法将变得无能为力，因此，在后来的研究中，国内外学者重点使用近似算法或启发式算法，
			主要有遗传算法、模拟退火法、蚁群算法、禁忌搜索算法、贪婪算法和神经网络等。

			哈密顿图（哈密尔顿图）（英语：Hamiltonian path，或Traceable path）是一个无向图，由天文学家哈密顿提出，
			由指定的起点前往指定的终点，途中经过所有其他节点且只经过一次。
			在图论中是指含有哈密顿回路的图，闭合的哈密顿路径称作哈密顿回路（Hamiltonian cycle），
			含有图中所有顶点的路径称作哈密顿路径。）
		2. 信息论下界





















