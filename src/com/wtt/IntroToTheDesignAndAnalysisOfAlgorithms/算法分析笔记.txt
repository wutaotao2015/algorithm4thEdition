1. 绪论
2. 算法效率分析基础
3. 蛮力法
4. 减治法
5. 分治法
6. 变治法
7. 时空权衡
8. 动态规划
9. 贪婪技术
10. 迭代改进
11. 算法能力的极限
12. 超越算法能力的极限

chapter 1

设计过程
	理解问题，
	设计算法
	数据结构
	算法描述
	正确性证明
	算法分析
	为算法写代码

重要的问题类型
	排序: 稳定性与是否需要额外空间(在位)
	查找：
	字符串处理： 字符串匹配
	图： 最短路径，填色问题
	组合问题：
	几何问题： 最近对问题，凸包问题
	数值问题：

基本数据结构
	线性数据结构： 数组，链表  栈，队列，优先队列
	图： 无向图，有向图。
		邻接矩阵，邻接链表
		加权图： 权重矩阵或成本矩阵 加权的邻接链表
	树： 即连通无环图  |E| = |V| - 1
		有根树： 顶点v的深度是根到v的简单路径的长度。
			树的高度是根到叶节点的最长简单路径的长度。（有些教材定义为树包含的层数，这样的高度比路径长度大1）
		有序树： 二叉树，二叉查找树，多路查找树
		二叉树： logN <= h <= n-1
		对于任意的有序树，如果每个节点都只包含2个指针，左指针指向该节点的第一个子女，
		而右指针指向该节点的下一个兄弟，此种方法为先子女后兄弟表示法（first child-next sibling representation).
		这样可以将任意一棵有序树转换成一棵二叉树。
	集合： 位向量表示法，以大量存储空间为代价
				线性列表结构来表示
	字典：从集合中查找，新增和删除一个元素，即动态内容的查找。


chpater 2

分析框架：
	输入规模
	运行时间： 由于具体时间受设备影响，应以基本操作执行次数为准（即内循环执行次数）
			T(n) = Cop * C(n)
			如果C(n) = n(n-1) / 2 ~ n^2/2,则依据上述公式在输入规模翻倍时有T(2n)/T(n) ~ 4.
			所以仅关注指数和常数的增长
	最优，最差和平均效率：
		最优：即某种输入可以得到最小的C(n)值，即内循环次数最小
		平均效率：不是简单的求平均数，而是根据不同的输入类型结合概率分布得出结果
		摊销效率： 多次运行，从而避免单次执行的最差效率
渐进符号和基本效率类型：

	O(g(n)): 增长次数小于等于g(n)的函数集合
	Ω(g(n)): 增长次数大于等于g(n)的函数集合
	Θ(g(n)): 增长次数等于g(n)的函数集合
	即O是上界，Ω是下界，对于Θ有对于所有的n>=n0来说，c2g(n)<= t(n) <= c1g(n)

	有用特性： 算法由2个连续的部分组成，其总体性能由性能较差的部分决定

利用极限比较增长次数： lim(n->∞) t(n)/g(n)的值

非递归算法的数学分析：

	1. 决定用哪个(哪些)参数表示输入规模
	2. 找出基本操作（内循环）
	3. 基本操作次数是否只依赖输入规模，若不是，需要对最差，最优，平均效率分别进行研究
	4. 建立基本操作次数的求和表达式
	5. 至少确定该公式的增长次数.

递归算法的数学分析：

	1. 决定用哪个(哪些)参数表示输入规模
	2. 找出基本操作（内循环）
	3. 基本操作次数是否只依赖输入规模，若不是，需要对最差，最优，平均效率分别进行研究
	4. 对于基本操作的执行次数，建立一个递推关系和对应的初始条件
	5. 解递推式或确立其增长次数


chapter 3 蛮力法

基于问题的描述和定义直接解决问题的办法
1. 选择排序，冒泡排序
2. 顺序查找，蛮力字符串匹配
3. 最近对和凸包问题
4. 穷举查找
5. 深度优先查找和广度优先查找
	dfs: 树向边，回边
	bfs: 树向边，交叉边

chapter 4 减治法

原问题和子问题的关系，可以从顶至下（递归）或从底向上（也叫增量法）解决。
1. 减去一个常量（考虑n-1的情况）
2. 减去一个常量因子（大多数应用因子为2）
3. 减去的规模是可变的（计算gcd的欧几里得算法）

1. 插入排序
	从顶向下思考: 对n个数进行排序，假设前面n-1个数已经排好了，
	最后一个数要排序应遍历前面的数列，插入进去从而实现有序，这是递归实现
	但从底向上实现效率更高,n从1开始循环增长到n
2. 拓扑排序
	1. 基于dfs算法的逆后序排列
	2. 基于减治法的逐个删除入度为0的顶点
	上面得到的解不同，所以可以有多个可选解
3. 生成组合对象的算法
	1. 生成排列：
		从底向上生成排列，最小变化算法（minimal change)
		johnson Trotter（对较小的n生成排列）算法
		按字典序排列算法
	2. 生成子集
		所有集合子集的集合称为幂集
		与子集一一对应的位串
		最小变化的生成位串： 二进制反射格雷码（它是循环的，最后一个位串与第一个位串只相差一位）BRGC算法
4. 减常因子算法
	1. 二分查找
	2. 假币问题： 找出一堆硬币中的假币。（将硬币分成3堆要比分成2堆要好）
	3. 俄式乘法： 为计算机通过移位即可完成二进制的折半和加倍提供了基础
	4. 约瑟夫斯问题： （这个故事告诉我们给别人干活时，明白领导的真正意图非常重要）
		每个人从1开始轮流报号，如报1的人杀死号码为2的人，依次进行
		J(2k) = 2J(k) - 1
		J(2k+1) = 2J(k) + 1
		闭合式最佳解： J(6) = J(110|2) = J(101|2) = J(5) 二进制向左循环移位一次

5. 减可变规模算法

	1. 计算中值和选择问题
		寻找中值： lomuto划分 用于划分的2个下标
		快速排序
	2. 插值查找
		对于一个有序的列表，通过线性公式求出待查找值v对应的x下标值，比较A[x]与v的值，比较后再减小规模
		类似于在字典靠前的部分查找单词book
		小规模排序二分查找更快，更大规模插值查找更快
	3. 二叉查找树的查找和插入
		根据树的形状和高度的不同，相同的数据减小的规模无法确定，所以是可变的
	4. 拈游戏
		类似象棋中局面概念一样，每次拿1<=n<=m个棋子，n=0，m+1，...是败局
		从底向上分析，通过数学归纳法可以得到赢或输的模式
		对于多堆的棋子，棋子个数的二进制之和若包含一个1，则当前局面为胜局，
		若和中全部为0时，则当前局面为败局。

chapter 5 分治法

	1. 将一个问题划分成若干子问题，最好子问题规模相同
	2. 对这些子问题求解
	3. 有必要时合并子问题的解
通用分治递推式：
T(n) = aT(b/n) + f(n) f(n)是将结果合并起来所消耗的时间
即原问题可以分成b个子问题，其中a个需要求解。
当a = 1时，即只需要解决一个问题时，即变成减常因子算法

1. 归并排序
2. 快速排序
	Hoare划分： 从左右两端同时扫描再交换的算法
	对于严格递增已经有序的数组，快排的效率是最差的，所以一般在排序前需要打乱数组
3. 二叉树遍历及其相关特性
	前序： 根左右
	中序: 左中右
	后序： 左右根
4. 大整数乘法和Strassen矩阵乘法
	1. 大整数相乘
		相同位数的乘法（不同可以前面补0）,分成2半分治处理。
		即发现两个2位数相乘可以不用4次乘法运算，通过分治3次就可以实现
		即其效率不是普通的n^2,而是n^1.5(log2 3)
		java中的BigInteger
	2. Strassen矩阵乘法
		对于2个2X2的矩阵，普通算法需要8次乘法，4次加法；
		Strassen算法需要7次乘法，18次加减法，当阶数趋近于无穷大时，其效率更高
		对于高阶的矩阵，可以用0补全划分成(n/2) X (n/2)的矩阵
		因为n阶矩阵的乘法得到的结果是n阶的，它的每一个元素都是左边的行元素和右边的列元素相乘得到，
		即n^2个元素中的每个元素都是经过n次乘法得到的，所以一共需要的乘法运算次数是n^2 * n = n^3个。
		Strassen通过递推式M(n)=7M(n)，M(1) = 1可以得出
		M(n) = n ^ 2.87(n ^ log2 7)
		同样通过递推式可以得出Strassen额外需要的加法次数的增长次数与乘法相同
		目前矩阵乘法最快的算法达到了n^2.376,而其理论下界是n^2
5. 用分治法解最近对问题和凸包问题
	1. 最近对问题
		在x坐标轴的中位线上画一条垂线，将点划分成两半进行分治处理
		然后在归并左右两边的最短距离时在一个矩阵内考虑即可。
		这与归并排序算法很相似
	2. 凸包问题
		快包算法： 和快排类似
		相当于一刀切开西瓜，上面一半叫上包，下面一半叫下包，
		在上包中找到距离切开线最远的点，使得三角形pl pMax pr 面积最大
		三角形外的2个半弧形即是所求上包的2部分，继续用三角形重复切分这个过程，知道上包为空，
		再将所有pMax点联合起来即可得到上包的所有极点。
		下包重复这个过程，即可得到整个的凸包。
		（代码实现时，三角形的面积可以用行列式的一半来计算，AB,AC的叉乘/外积是平行四边形的面积，
		三角形是它的一半）

Chapter 6 变治法

	3中主要类型
	1. 实例化简：变为更简单的实例，该新实例有一些特殊的属性，使得它可以更容易被解决。
	2. 改变表现：变为同样实例的不同表现
	3. 问题化简：变为另一个问题的实例

1. 预排序
	1. 检验数组中元素的唯一性
		nlogn, n-1 整体性能是nlogn
	2. 模式计算
		找出列表中出现频率最高的数字（即模式）： 未排序前需要辅助的map集合记录每个不同数字的频率，最差是n^2,
			但经过预排序后，找出邻接次数最多的等值元素即可。
	3. 查找问题
		在列表中找到某个特定的元素，蛮力法n次比较，预排序nlogn,但如果多次查找，预排序更好。
一般处理几何计算问题需要预排序，上章的最近对和凸包问题就用到了；另外拓扑排序，基于贪婪技术的算法也用到了。

2. 高斯消去法
	通过初等变换得到一个上三角矩阵，x(n)通过最后一行解出，x(n-1)通过将x(n)代入n-1行求出。
	还需考虑到除数为0时直接进行行交换的情况，以及舍入误差的问题
	通过优化后其效率为n^3.
	1. LU分解
		利用高斯消去法的中间过程的乘数L和结果U，对任意的Ax = b的方程组，因为LU = A
		其等价于LUx = b, 设Ly = b => y的结果，再求 Ux = y => x的结果。
	2. 计算矩阵的逆
		想要求逆，即求出逆矩阵的n^2个未知系数，可以利用LUx(j) = e(j)求出逆矩阵的第j列（1<=j<=n),e(j)代表单位矩阵的第j列。
	3. 计算矩阵的行列式
		按照行列式的递归定义求解行列式，detA = sum（1，n)s(j)a(1j)detA(j)
		它求detA(n)需要n!的数量级，利用高斯消去法，
		因为一个上三角矩阵的行列式等于其主对角线上的元素的乘积。
		 Ax = b;方程的系数矩阵detA != 0时，这个方程才有唯一解（行列式是线性变换的比率大小！！！）
		 可以用克拉默法则来求解。xj = detAj / detA; An是A的第j列用b替换得到的矩阵

3. 平衡查找树
	1. AVL树
		通过旋转将一颗不平衡的二叉查找树转化为平衡的树的过程即是实例化简的过程。
		平衡二叉树指每一个节点的高度差是最多为1的二叉查找树。
		4种旋转：
		1. 右单旋 R
		2. 左单旋 L
		3. 左右双旋 LR （先左旋下一层子树，再右旋上一层子树）
		4. 右左双旋 RL （先右旋下一层子树，再左旋上一层子树）
	2. 2-3树 （改变表现）
		一个3-节点包含2个键，它同是也是有序的，所有的叶子都位于同一层，即它是高度平衡的
		2-3树有一种重要的一般性形式，即B树。

4. 堆和堆排序(改变表现)
	1.堆的概念
		一颗完全二叉树，每层都是满的，除了最后一层最右边的元素可能为空；
		堆特性： 每个节点的键大于等于子女的键。
		键值是从上到下排序的，即从根到任意一个叶子的路径上，键值的序列是递减的。
		但不存在左右的关系，即同一节点的左右子树之间没有关系。
		用数组来实现堆：
			父母节点在前n/2个位置中，最底层的叶子节点在后n/2个位置中
			父母节点为i(1<=i<=[n/2]),其子女为2i和2i+1。
			叶子节点为i(2<=i<=n),其父母为[i/2].
		构造堆：
		1.自底向上： sink.
		2. 自顶向下： swim.
	2. 堆排序
		1. 构造堆。
		2.删除根（最大键），放到数组后面，重新堆化后重复这个过程直到排序完成。
		堆排序的时间效率也为nlogn
5. 霍纳法则和二进制幂(改变表现)
	1. 霍纳法则
		已知x,求多项式的值，以及该多项式的特殊情况求x^n的值。

			p(x) = a(n)x^n + a(n-1)x(n-1) + ... + a1x + a0;

		把x作为公因子提出来变为
			p(x) = (...(a(n)x + a(n-1))x+...)x + a0
		由其特定模式即可以得到霍纳法则的算法
		算法代码
		Horner(int[] P, x) {
		 int p = P[n];
		 for (int i = n-1; i >= 0; i--) {
		 	p = x * p + P[i - 1]
		 }
		 return p;
		}
		霍纳法则用n次乘法不仅求出了x^n的值，还求出了其他n-1项的值（中间结果）。
		综合除法算法，对于某些特定x0，中间结果为商的系数，最终结果为余数。
	2. 二进制幂
		用霍纳法则计算x^n时，退化成了蛮力的自乘，没有效果。
		一个正整数的二进制表示,如13 = 1101，
		则13 = 1 * 2^3 + 1 * 2^2 + 0 * 2^1 + 1 * 2^0;
		x^n = x^p = x ^ (b(I)2^I + ... + b(i)2^i + ... + b(0))
		对p使用霍纳法则，观察x^n的结果，可以得出规律。
		算法
		leftRightBinaryExponention(a, int[] b){

			int product = a;
			for(i = I - 1; i >= 0; i--) {
				product = product * product;
				if(b[i] == 1) product = a * product;
			}
			return product;
		}
		该算法将a^n由蛮力的n-1次乘法变为log(n)次（二进制表示的位数长度为log(n))
		另不用霍纳法则，对指数进行列项，从小向大平方，即从右向左。
		RightLeftBinaryExponention(a, int[] b) {
			int term = a;
			if(b[0] = 1){
				product = a;
			}else{
				product = 1;
			}
			for(int i = 1; i <= I; i++) {
				term = term * term; // a^2
				if(b[i] == 1) {
					product = product * term; // 以a^2增长
				}
			}
			return product;
		}
		这也是对数级别的，可以不直接使用对数表示。
6. 问题化简
	即将目标问题简化为某个有已知算法的问题的过程。
	前面求x^n化简为可以应用霍纳法则的多项式问题，
	以及凸包中判断一个点在某条直线左边的问题简化为求某个行列式的符号问题
	都属于问题化简类别。
	1. 求最小公倍数。
		在已知欧几里得算法求gcd的情况下，如何求最小公倍数？
		根据定义发现gcd * lcm = m * n;
		即 lcm = m * n / gcd;
		从而将lcm的问题转化成了gcd的问题。
	2. 计算图中的路径数量
		图的邻接矩阵的n次幂可以指示出2个顶点之间的路径的数量
	3. 优化问题的化简
		已知一个函数的最大值，怎么求最小值？
		可以发现	 minf(x) = -max(-f(x))
		求函数f(x)极值点的过程也是微积分的过程，该问题转化为求f'(x)=0的问题，变为解方程
	4. 线性规划
		很多决策最优化问题都可以转化为线性规划问题
		该问题的经典解决算法是单纯形法和卡马卡算法，而对于离散的线性规划问题还没有一个多项式级的求解算法
		背包问题也可以转化为线性规划问题，虽然效率不高，但可以用来检验算法的正确性。
	5. 简化为图问题
		很多问题可以转化为图的问题，顶点表示可能的状态，边表示状态的转移，这种图叫做状态空间图（state-space graph).
		农夫带狼，羊，白菜过河的问题是从状态pwgc||变为状态||pwgc的最短路径问题
		状态空间图是人工智能的一个重要主题。

Chapter 7 时空权衡
	空间换时间
		输入增强： 对问题的部分或全部输入做预处理，然后将获得的额外信息进行存储以加速后面问题的解决。
		预构造：在实际之前处理并只涉及存储结构。
	动态规划： 重复子问题的解记录在表中。

	1. 计数排序
		比较计数排序： 用一个列表记录每个元素比它小的元素的个数，按此进行排序。
		分布计数： 根据频率和分布值对列表从右往左扫描依次放入新数组中，
		放入位置由分布值（该元素最后出现的位置）确定，每放入一个元素分布值减一，直到扫描完成。

		该算法为线性效率，因为其仅仅对列表扫描2遍，第一遍统计频率，并由频率得出分布值。
		第二遍扫描元素依次将其放入正确位置，它比快排算法效率还高的原因是因为它的元素值的取值区间已知。

	2. 字符串匹配中的输入增强技术
		蛮力法效率最差为O(nm),平均为O(n+m)
		对模式进行预处理得到的信息存储在表中，在查找中使用这些信息从而提高效率。
		Knuth-Morris-Pratt算法和Boyer-Moore算法（区别是前者从左往右匹配模式，后者从右向左）
		1. Horspool算法
			1. 用模式的长度m和模式及文本中用到的字母表构造一个移动表，它的索引是字母，值是移动的距离。
			2. 将模式与文本开始处对齐。
			3. 开始匹配，要么所有m个字符都匹配，要么遇到一对不匹配的字符，那么向右移动模式的最后一个字符
			在移动表中的距离。
		Horspool算法最差效率为O(nm),但对于随机文本，效率为O(n)

		2. Boyer-Moore算法
			1. 与Horspool算法一样构造坏符号移动表
			2. 构造好后缀移动表
			3. 将模式与文本开始处对齐
			4. 进行实际匹配
			实际使用还是Horspool算法较多
	3. 散列法
		开散列： open hashing 也叫分离链separate chaining
		闭散列： closed hashing 也叫开式寻址opening addressing

		1. 开散列（分离链)
			hashMap的实现方式
			散列函数大致均匀的将n个键分布在散列表的m个单元格中，比率α = n/m称为负载因子，它也是单个链表的长度
			成功查找平均需要查找一半的长度，即1+α/2,不成功查找为α。
			负载因子最好和1相近，远小于1则有很多空链表，远大于1则链表长度太长，查找时间太长。
			在与1相近的情况下，经过常数时间的散列函数计算，比较1,2次（依据α的值）就可以完成查找。

		2. 闭散列（开式寻址）
			线性探测法
				同样经过散列函数找到具体数组的位置，如果冲突就向后检查下一格，如果为空就插入。
				一系列的单元格称为聚类，聚类增大影响性能，可以用双散列法，该法在碰撞发生后不是向后逐个检查，
				而是根据一个质数跳跃检查，但当表快满时，性能也会恶化，次时应该重散列，把所有的键放到一个更大的表中。

		渐进时间效率（散列法平均O(1),最差O(n);平衡二叉树平均和最差都是O(lgN))
		有序性 散列法经过散列后有序性丢失。
		可扩充散列法可以存储磁盘上大型字典，散列得出某个存储段，将其中所有键转到内存中再进行具体查询。
	4. B 树
		最重要的索引结构是B树。
		B树是2-3树的扩展，一个节点可以有多个键。
		一个次数为m(m>=2)的B树的特征（次数=最大键数-1？）
		1. 树的根要么是一个叶子（所有的键都在一个节点中，每个键的左右都是空指针），
			要么有2到m个子女（一个节点有2到m个键）
		2. 除了叶子和根，中间的父母节点只有m/2到m-1个键（由左右子树的性质决定，最少的键数=根下最多的子女=m/2)
		3. 这颗树是完美平衡的，它的所有叶子都在同一层上。
		当用B树存储一个大型数据文件时，B树的节点通常和磁盘的页相对应，所以访问的树节点个数成了性能指标，
		这个个数为树的高度加一
		经过B树的性质（一个节点包含的最少键数，叶子层至少包含的节点数）推导可以得出
		在B树中查找是一个效率为log(n)的操作，在实际的应用中磁盘访问次数很少超过3次。
		B树的插入和删除也是log(n)级别的操作。
		可以把数据记录连续插入初始为空的树中来构造一棵B树，这时叶子和上层节点中的键组成了一颗作为索引的B树，
		整个结构也被称为B+树。
	一般来说，空间换时间更为普遍。

chapter 8 动态规划
	例子：斐波那契数列的从底向上解决，根据递推关系式只存储最后2个元素值即可解决
	最优化法则： 任一问题的最优解都是由其子实例的最优解构成的。
	此法则绝大多数情况都是成立的。

	1. 三个基本例子
		1. 币值最大化问题
			一排硬币，币值并不一定两两不同，如何选择硬币，使得其原始位置不相邻的情况下，总金额最大？
			F(n) = max{c(n) + F(n-2), F(n-1)} n > 1
			F(0) = 0, F(1) = c1
			CoinRow(int[] C) {
				F[0] = 0;
				F[1] = C[1];
				for(int i=2;i<=n;i++){
					F[n] = max(F[i-2]+C[i], F[i-1]);
				}
				return F[n];
			}
			具体哪些硬币需要回溯算法找到最大值
		 2. 找零问题
		 	需找零金额为n,最少用多少个d1<d2<...<dm的硬币？
		 	F(n) = min{F(n-dj)}+1  n>=dj
		 	F(0) = 0;
		 	F(n)需要找到所有的F(n-dj)中最小的值
		 	ChangeMaking(D[1...m], n){
		 		F[0] =0;
		 		for(int i = 1; i <= n; i++) {
		 			temp = infinite,j = 1;
		 			// 将temp与每个F[n-dj]比较，找出最小值
		 			while(j <= m && i >= D[j]) {
		 				temp = min(F[i-D[j]], temp)
		 				j++;
		 			}
		 			F[i] = temp + 1;
		 		}
		 		return F[n];
		 	}
		 	具体哪些硬币需要回溯算法找到最小值
		 3. 硬币收集问题
		 	一个n X m的木板上放有一些硬币，一个机器人从左上角去往右下角，怎么收集最多的硬币？
		 	F(i,j) = max{F(i-1,j), F(i,j-1)} + c(ij),  1<=i<=n,1<=j<=m
		 	F(0,j) = 0, 1<=j<=m; F(i,0) = 0, 1<=i<=n
		 	有单元格(i,j)中有硬币，c(ij) = 1,否则为0
			RobotCoinCollection(C[1..n, 1...m]) {
				F[1,1] = C[1,1],
				for(int j = 2; j <= m; j++) {
					F[1, j] = F[1, j-1] + C[1,j];
				}
				for(int i=2; i <= n; i++) {
					F[i, 1] = F[i - 1, 1] + C[i, 1];
					for(int j = 2; j <= m; j++) {
						F[i, j] = max(F[i - 1, j], F[i, j - 1]) + C[i, j];
					}
				}
				return F[n, m];
			}
	2. 背包问题和记忆功能
		1. 背包问题
			用2个维度解决这个问题，一个维度i是序号，第一个物品的重量是w1,价值是v1;
			另一个维度j是总重量w.
					|	max{F(i-1,j), v(i)+F(i-1, j-w(i))},  j-w(i)>=0 //第i个物品能放进背包
			F[i,j] =| 	F(i-1, j),  //第i个物品不能放进背包
			j>=0时，F[0,j] = 0; i>=0时，F[i,0] = 0
			要求F[n,W]
			具体求解可以画出动态规划表，通过回溯表的计算过程可以得出最优解的物品列表
			时间和空间效率都是O(nW),求解具体过程为O(n)
		2. 记忆化(Memory Function)
			针对自顶向下的算法，只对必要的子问题进行求解，可以像自底向上一样构造一个表，
			表中数据全部初始化为null, 取值时如果为null,计算后将值放入其中，若不为null,则取该值，
			避免第二次计算。

			递归记忆法自顶向下解决背包问题
			MFKnapsack(i, j) {
				//除了0行和0列初始化为0外，其他单元格初始化为-1
				if (F[i, j] < 0) {
					if(j < Weighs[i]) {
						value = MFKnapsack(i-1, j);
					}else{
						value = max(MFKnapsack(i-1, j), Values[i]+MFKnapsack(i-1, j-Weighs[i]));
					}
					F[i,j] = value;
				}
				return F[i,j];
			}
			求解MFKnapsack(n, w)即可。
			记忆功能时间效率和从底向上是一样的，空间效率在自底向上是最高的。
	3. 最优二叉查找树
		有n个从小到大排列的数，每个数被查找的概率不一定相同，需要结合概率求平均最少的查找次数和树结构？
		以a(k)为根，C(i,j)代表从ai到aj区间的查找次数，最后要求C(1,n)（a1到an的平均查找次数）
		这里的平均结合概率来计算
		C(i,j)
		 = min{p(k) * 1 + sum(s, i, k-1)(p(s) * (ak左子树层数+1)) + sum(s, k+1, j)(p(s) * (ak右子树+1))}
		 = min{C(i, k-1) + C(k+1, j)} + sum(s,i,j)p(s)
		1<=i<=n+1,C(i,i-1) = 0(为负区间，空树)
		1<=i<=n, C(i,i) = p(i)(根据上述公式可以求得)
		根据上述2个初始条件可以画出二维图（行从1开始到n+1,列从0开始到n)，这样对角线全为0,其(i,i)对应斜线为对应概率值，
		根据递推公式直到求出最右上角的值。
		把每次求得最小值的k值（即每个区间的根节点a(k）记录下来即可以得到具体的二叉树图

	4. Warshall算法和Floyd算法
		1. Warshall算法
			可以用dfs或bfs生成传递闭包，但是这需要针对每个顶点都遍历一次图，效率较低，更好的算法为Warshall算法
			R0,R1,...Rk,...Rn
			R0意味着路径中没有中间顶点，Rk意味着路径的顶点序号不大于k
			可以分析发现，R(ij)(k) = 1时可能的路径有2种情况，不包括顶点k,则R(ij)(k-1) =1,
			或者包括顶点k,则可以将路径化简为R(ik)(k-1) = 1并且R(kj)(k-1) = 1.
			该递推关系可以简化为R(ij)(k) = R(ij)(k-1)	or {R(ik)(k-1) And R(kj)(k-1)}
		2. 计算完全最短路径的Floyd算法













